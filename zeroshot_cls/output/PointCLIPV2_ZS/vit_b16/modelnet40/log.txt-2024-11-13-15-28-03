Collecting env info ...
** System info **
PyTorch version: 1.13.1
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.4 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.10.10 (main, Mar 21 2023, 18:45:11) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.13.0-30-generic-x86_64-with-glibc2.31
Is CUDA available: True
CUDA runtime version: Could not collect
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 2080 Ti
Nvidia driver version: 515.105.01
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] numpy==1.23.5
[pip3] pytorch3d==0.7.3
[pip3] torch==1.13.1
[pip3] torch-cluster==1.6.1
[pip3] torch-geometric==2.3.1
[pip3] torch-scatter==2.1.2
[pip3] torchaudio==0.13.1
[pip3] torchvision==0.14.1
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0           py310h7f8727e_0  
[conda] mkl_fft                   1.3.1           py310hd6ae3a3_0  
[conda] mkl_random                1.2.2           py310h00e6091_0  
[conda] numpy                     1.23.5          py310hd5efca6_0  
[conda] numpy-base                1.23.5          py310h8e6c178_0  
[conda] pytorch                   1.13.1          py3.10_cuda11.7_cudnn8.5.0_0    pytorch
[conda] pytorch-cuda              11.7                 h778d358_3    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] pytorch3d                 0.7.3           py310_cu117_pyt1131    pytorch3d
[conda] torch-cluster             1.6.1                    pypi_0    pypi
[conda] torch-geometric           2.3.1                    pypi_0    pypi
[conda] torch-scatter             2.1.2                    pypi_0    pypi
[conda] torchaudio                0.13.1              py310_cu117    pytorch
[conda] torchvision               0.14.1              py310_cu117    pytorch
        Pillow (9.4.0)

Loading trainer: PointCLIPV2_ZS
Loading dataset: ModelNet40
***** Dataset statistics *****
  Dataset: ModelNet40
  # classes: 40
  # train_x: 9,840
  # val: 2,468
  # test: 2,468
Loading CLIP (backbone: ViT-B/16)
Loading evaluator: Classification

Trainer:  <trainers.zeroshot.PointCLIPV2_ZS object at 0x7fed135276a0>
Do evaluation on test set
=> result
* total: 2,468
* correct: 1,573.0
* accuracy: 63.74%
* error: 36.26%
Save feature: ============================
Save labels: =============================
Total time: 36.73057961463928
Point cloud shape:  torch.Size([1, 2048, 3])
Text feat shape:  torch.Size([1, 512])
Text feat:  tensor([[ 3.5034e-01, -1.3330e-01,  9.3689e-02, -3.0899e-03, -2.3056e-02,
          4.7668e-02,  2.1216e-01, -2.7637e-01,  2.6489e-01,  7.0801e-02,
          5.8624e-02, -2.1252e-01, -1.1444e-01,  3.0298e-01,  5.9180e-01,
         -2.1899e-01, -2.7496e-02, -3.4393e-02, -3.7476e-01, -7.7248e-03,
          8.7036e-02, -4.5508e-01, -4.3164e-01,  1.9519e-01,  2.8320e-02,
         -1.1963e-01,  3.4131e-01,  1.9019e-01, -1.0638e-01, -1.4551e-01,
         -7.5989e-02,  1.7212e-01, -2.1265e-01,  2.1988e-02,  6.9824e-01,
          6.9702e-02,  3.1201e-01, -7.2449e-02, -1.5088e-01,  2.8656e-02,
          5.5389e-03,  1.6617e-02,  4.4946e-01, -9.0698e-02,  5.9128e-03,
         -6.1523e-02,  9.7351e-02,  1.4172e-01, -2.6550e-02, -2.7252e-02,
         -7.2510e-02, -3.6108e-01,  3.5352e-01, -3.7207e-01, -1.3770e-01,
          2.7783e-01, -2.9126e-01, -4.9103e-02, -1.2219e-01,  1.7542e-01,
         -3.6572e-01, -1.3757e-01,  2.3254e-01, -7.1167e-02, -2.3547e-01,
          2.9077e-01,  7.4646e-02, -1.1804e-01, -4.6295e-02,  7.4280e-02,
          2.7905e-01,  1.4819e-01,  1.7603e-01, -2.0081e-01,  1.2976e-01,
         -1.7761e-01, -2.6099e-01, -6.8481e-02, -7.8369e-02,  1.2006e-01,
         -2.8296e-01, -1.2671e-01, -2.1985e-01, -1.7590e-01, -2.7637e-01,
         -1.7236e-01,  5.6183e-02, -2.4609e-01, -2.6758e-01, -1.2854e-01,
          4.2297e-02,  8.2031e-02,  5.9814e-02,  3.4473e-01, -1.1185e-02,
         -2.5610e-01, -1.6875e+00,  2.5894e-02, -6.5283e-01, -1.8262e-01,
          1.4697e-01, -1.3062e-01, -1.0486e-01,  4.9976e-01,  4.4580e-01,
          1.4380e-01, -6.0364e-02, -5.2637e-01, -1.4368e-01, -1.3416e-01,
          2.7740e-02,  1.3599e-01,  3.4637e-02,  2.4765e-02,  4.0955e-02,
         -1.7822e-01, -3.4375e-01,  2.6978e-01, -2.6343e-01,  1.3904e-01,
         -3.9697e-01,  6.7725e-01,  1.2634e-01,  1.0913e-01,  8.0933e-02,
         -4.5532e-01, -1.2549e-01,  3.1201e-01,  1.3159e-01, -2.7588e-01,
         -2.5349e-03,  1.8555e-01, -6.7322e-02,  2.9770e-02,  7.0190e-02,
          3.8727e-02, -2.9419e-01,  2.2314e-01, -2.0959e-01,  6.7932e-02,
         -2.9321e-01,  2.3096e-01,  9.2529e-02, -2.4857e-02,  2.1362e-01,
         -8.9722e-02, -3.1079e-01,  3.9819e-01, -2.9297e-01,  1.4734e-01,
         -1.9434e-01, -2.2110e-02,  2.4377e-01, -1.5625e-01, -9.0881e-02,
         -1.1224e-01,  9.5093e-02, -6.9702e-02, -1.7432e-01, -1.9690e-01,
         -3.6182e-01, -2.7271e-01, -3.7646e-01, -1.9873e-01,  1.2030e-01,
          4.3188e-01, -1.2964e-01,  8.7695e-01,  2.6794e-02, -3.8184e-01,
         -9.3384e-02,  6.7329e-03, -2.9370e-01, -6.8426e-04, -9.6130e-02,
          1.7468e-01,  8.9600e-02,  1.3293e-01,  9.4604e-02,  3.3838e-01,
          2.5464e-01,  3.6591e-02, -2.5537e-01, -1.0547e-01, -4.2419e-02,
         -1.2457e-01, -8.3984e-02, -7.9407e-02, -1.0437e-02,  2.4878e-01,
         -9.4055e-02,  6.9031e-02, -7.4646e-02, -2.4023e-01,  5.3174e-01,
          4.1901e-02,  1.9702e-01,  1.0382e-01, -1.9543e-01,  2.1875e-01,
          1.7090e-01,  1.3257e-01, -1.8396e-01,  1.3733e-01,  1.0913e-01,
         -2.2632e-01, -1.7688e-01, -2.2400e-01,  6.0791e-02,  1.8164e-01,
          3.9160e-01,  1.7151e-01,  5.4688e-01,  6.2744e-01,  2.7771e-02,
         -2.6207e-03, -3.2983e-01,  3.4912e-01, -4.0454e-01, -6.3281e-01,
         -1.7542e-01, -4.0131e-02,  1.3684e-01, -1.5002e-01,  8.0994e-02,
          1.7749e-01,  3.0518e-01, -1.1200e-01, -3.2642e-01, -5.3497e-02,
          8.5754e-02, -4.0015e-01,  1.6003e-01, -1.4233e-01, -3.5919e-02,
         -8.5083e-02,  1.0345e-01, -8.0261e-03, -4.8755e-01,  4.4458e-01,
          1.8428e+00, -1.0834e-01, -1.4697e-01,  8.9722e-02,  2.6416e-01,
          3.9795e-02,  2.3865e-01, -2.3364e-01, -3.4253e-01,  2.4634e-01,
         -3.7964e-01,  1.3831e-01,  6.8054e-02,  7.7698e-02,  1.0583e-01,
         -1.0071e-01, -1.0114e-01,  4.6191e-01, -2.2400e-01, -2.4994e-02,
         -1.7212e-01,  6.9153e-02, -2.2034e-01, -4.1748e-01,  3.5217e-02,
          2.5635e-01,  9.3079e-02,  1.6754e-02,  5.4626e-02,  3.8086e-01,
         -1.9312e-01,  8.1726e-02,  3.2562e-02, -2.5040e-02, -1.1635e-02,
          2.0728e-01,  4.8169e-01, -6.0333e-02, -2.3666e-02, -4.7455e-02,
         -1.2201e-01, -5.0842e-02, -1.9067e-01, -1.1011e-01,  1.4966e-01,
          4.9896e-02, -7.2021e-02, -4.7760e-02,  9.4299e-02, -4.1895e-01,
          2.8369e-01,  6.5381e-01,  2.7686e-01,  1.4359e-02, -4.7461e-01,
         -2.6587e-01,  6.1719e-01,  4.8584e-01, -2.6685e-01, -5.8807e-02,
          1.6516e-01, -4.2578e-01, -5.5420e-02,  3.7500e-01, -1.6479e-01,
         -1.8494e-01,  1.4307e-01, -7.1960e-02,  3.5889e-01, -1.1725e-01,
         -7.6660e-02, -1.1559e-03, -5.7129e-01,  4.0747e-01,  1.3550e-01,
         -2.1240e-01,  1.6455e-01,  2.4765e-02, -1.1652e-01,  4.9316e-01,
          2.3169e-01,  3.4058e-02,  9.8022e-02,  2.2791e-01,  3.5065e-02,
         -2.9709e-02, -4.0527e-02, -4.3799e-01,  1.0156e-01, -9.7885e-03,
          5.7983e-02, -1.7505e-01,  4.1168e-02, -2.7191e-02,  8.5693e-02,
          6.3904e-02, -9.1675e-02, -3.7109e-01,  4.3121e-02,  4.3304e-02,
         -9.6069e-02, -2.5528e-02, -5.9326e-01,  2.5415e-01, -2.3230e-01,
         -3.6011e-01, -8.3130e-02,  2.0300e-01,  3.5718e-01,  1.0785e-01,
          2.8711e-01,  2.8589e-01,  1.8140e-01,  1.3191e-02,  4.7180e-02,
          4.5868e-02,  5.3986e-02, -1.9250e-01, -6.6528e-02, -1.6754e-02,
          3.1616e-01,  1.7078e-01,  8.1641e+00, -2.3926e-01,  3.2666e-01,
         -2.1591e-02,  4.9667e-03,  1.3855e-01,  2.2546e-01,  5.6348e-01,
          1.2561e-01,  4.8022e-01, -2.1594e-01, -1.3824e-02,  8.1116e-02,
         -1.7578e-02,  9.3628e-02, -2.3224e-02,  1.1395e-01,  1.4282e-01,
          1.6541e-01, -2.2119e-01,  1.2476e-01,  1.2244e-01, -2.5977e-01,
         -6.9504e-03, -2.7161e-02,  4.2163e-01,  1.8204e-02,  5.3253e-02,
          2.0889e-02,  7.0618e-02, -2.9175e-01,  4.5837e-02, -3.0228e-02,
         -2.5244e-01, -8.2520e-02, -1.1578e-01, -2.8394e-01, -1.6553e-01,
         -1.5857e-01, -1.4246e-01,  3.0664e-01,  4.4823e-03,  1.6431e-01,
          1.8555e-01, -3.1787e-01, -6.2561e-03, -1.9519e-01,  2.1469e-02,
          1.6394e-01,  4.2542e-02,  2.8857e-01, -4.7070e-01,  2.8687e-01,
          3.1641e-01,  2.2327e-01,  9.9243e-02,  4.2383e-01, -2.4854e-01,
         -5.3223e-02, -5.9113e-02,  5.1270e-01,  1.3440e-01,  1.1414e-02,
          2.2278e-01,  2.1143e-01,  4.5728e-01,  3.4106e-01, -1.6602e-01,
         -2.5854e-01, -2.3462e-01,  2.3376e-01,  1.2878e-01,  2.5537e-01,
          2.2449e-01, -8.0200e-02,  4.3091e-02,  2.1225e-02, -2.3572e-01,
          1.6028e-01, -3.9429e-01,  1.8789e+00,  2.5000e-01,  6.7810e-02,
          1.2886e-02, -2.1619e-01,  1.1090e-01, -1.1841e-01,  1.0242e-01,
         -6.3232e-02, -6.6357e-01, -9.6680e-02,  1.3123e-01, -7.5684e-02,
          2.1985e-01,  2.1338e-01,  4.4946e-01,  9.2010e-03, -2.5415e-01,
         -1.7310e-01,  1.7566e-01,  5.0659e-02, -8.9172e-02, -2.3999e-01,
          1.3245e-01, -9.8206e-02,  6.4941e-01, -1.3074e-01, -1.1127e-01,
          8.3313e-02, -1.8173e-02,  7.6111e-02, -2.0984e-01,  4.2578e-01,
         -1.9495e-01,  3.5400e-01, -5.0049e-01,  1.3745e-01, -2.0737e-02,
          2.3193e-01,  1.1787e+00, -5.7648e-02,  2.6709e-01,  2.6221e-01,
         -3.4851e-02, -2.6782e-01, -3.5352e-01, -9.1797e-02, -2.1582e-01,
         -8.8989e-02, -1.4246e-01,  4.8071e-01, -2.1265e-01,  1.9617e-01,
         -4.4342e-02,  8.2031e-02, -2.8760e-01, -1.8567e-01, -5.3223e-01,
          4.9805e-01, -1.0730e-01,  1.5930e-01,  5.7281e-02,  1.5771e-01,
          4.7705e-01, -2.4255e-01, -4.0967e-01,  2.0142e-01, -1.9690e-01,
          2.9321e-01, -9.2651e-02]], device='cuda:0', dtype=torch.float16)
Image feat shape:  torch.Size([10, 512])
Image feat:  tensor([[ 0.0524, -0.0590,  0.0386,  ...,  0.0231,  0.0420,  0.0285],
        [ 0.0344, -0.0472,  0.0264,  ...,  0.0153,  0.0257,  0.0194],
        [ 0.0419, -0.0657,  0.0440,  ...,  0.0215,  0.0377,  0.0252],
        ...,
        [ 0.0358, -0.0416,  0.0342,  ...,  0.0077,  0.0341,  0.0332],
        [ 0.0321, -0.0619,  0.0355,  ...,  0.0037,  0.0203,  0.0299],
        [ 0.0447, -0.0424,  0.0285,  ...,  0.0081,  0.0164,  0.0341]],
       device='cuda:0', dtype=torch.float16)
Score:  tensor([0.2372, 0.2314, 0.2281, 0.2389, 0.2343, 0.2454, 0.2267, 0.2306, 0.2300,
        0.2311], device='cuda:0', dtype=torch.float16)
